{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec-skipgram.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arungovindm/word2vec-skipgram/blob/arch-1/word2vec_skipgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oTIqAD2bcYCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24735bf2-4215-4fe8-decf-6cc8cf5c6d02"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GJcvw7lzcl-C",
        "colab_type": "code",
        "outputId": "3b4ddb3a-4f34-422b-9e4b-a5cdbb92a5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('reuters')\n",
        "from nltk.corpus import reuters\n",
        "t=reuters.fileids()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GWewazDQgAUS",
        "colab_type": "code",
        "outputId": "4385837a-1cb0-4b49-d15d-932bdb5bf90c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "rem = set(stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0K3YrIQDdA-P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train=[]\n",
        "test=[]\n",
        "for a in t:\n",
        "    if a.startswith('training'):\n",
        "        train.append(a)\n",
        "    else:\n",
        "        test.append(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3YODVjJXe7B3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus=reuters.words(train)\n",
        "fdist = nltk.FreqDist(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owZyF16Hgdi1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filtered_corpus = []\n",
        "for w in corpus:\n",
        "  if not (w.isdigit() or w in rem or len(w)<3):\n",
        "    filtered_corpus.append(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHRMALicrn14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size=len(nltk.FreqDist(filtered_corpus))\n",
        "d=300 #dimensionality\n",
        "power =0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3KyEWrIRtJMe",
        "colab_type": "code",
        "outputId": "fe95654e-bc22-4047-8997-454dcacccb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "Z=0\n",
        "vocab = nltk.FreqDist(filtered_corpus)\n",
        "for a,b in vocab.items():\n",
        "  Z=Z+b**power\n",
        "print(Z)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "195801.74701170594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HnujZdnbCTAS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab = nltk.FreqDist(filtered_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jRr6oRLwJ4V4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_idx = dict()\n",
        "idx_word=dict()\n",
        "dict_count = dict()\n",
        "i=1\n",
        "for word, count in vocab.items():\n",
        "  word_idx[word]=i\n",
        "  idx_word[i]=word\n",
        "  dict_count[i]=count\n",
        "  i=i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "syr8_i-KE32Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labelled_corpus=[]\n",
        "for word in filtered_corpus:\n",
        "  labelled_corpus.append(word_idx[word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OK4QMJhoCUmq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del corpus, filtered_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWMFoIAfQ_zE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size = 2 #context window size\n",
        "neg=5 #number of negative samples\n",
        "target=[]\n",
        "context=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDxSdAEmT3Sk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(labelled_corpus)):\n",
        "  for j in range(window_size):\n",
        "    if i+j+1 < len(labelled_corpus):\n",
        "      context.append(labelled_corpus[i+j+1])\n",
        "      target.append(labelled_corpus[i])\n",
        "    if i-j-1 >=0:\n",
        "      context.append(labelled_corpus[i-j-1])\n",
        "      target.append(labelled_corpus[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6lXm2wAyZGrj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dict_prob=dict()\n",
        "for idx,count in dict_count.items():\n",
        "  dict_prob[idx]=(dict_count[idx]**power)/Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "COwl0eeeaVsG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unigram_sampling(dct):\n",
        "    rand_val = np.random.random()\n",
        "    total = 0\n",
        "    for k, v in dct.items():\n",
        "        total += v\n",
        "        if rand_val <= total:\n",
        "            return k\n",
        "    assert False, 'unreachable'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qooWWB_uP2ym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_train_instance(idx,neg):  #target word, context word and neg negative context samples\n",
        "  train_instance=[]\n",
        "  train_instance.append(target[idx])\n",
        "  train_instance.append(context[idx])\n",
        "  i=0\n",
        "  for i in range(neg):\n",
        "    train_instance.append(unigram_sampling(dict_prob))\n",
        "  return train_instance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LA14F-gBjFGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# building the neural net with tensorflow\n",
        "\n",
        "#model parameteres\n",
        "b=tf.Variable(tf.zeros(vocab_size,1))\n",
        "W=tf.Variable(tf.random_uniform((vocab_size,d),-1,1))\n",
        "\n",
        "\n",
        "#input\n",
        "w=tf.placeholder(tf.int32, (neg+2,1))\n",
        "\n",
        "#hidden layer\n",
        "H1=tf.reshape(tf.nn.embedding_lookup(W,w),[neg+2,d])\n",
        "v_w=tf.reshape(tf.nn.embedding_lookup(H1,[0]), [1,d])\n",
        "C = tf.reshape(tf.nn.embedding_lookup(H1,w[1:]),[neg+1,d])\n",
        "H2=tf.matmul(v_w,tf.transpose(C))\n",
        "\n",
        "#loss\n",
        "#prediction = tf.nn.sigmoid(tf.matmul(tf.transpose(v_w),v_c))\n",
        "#loss = -1*tf.log(prediction)\n",
        "#train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjIOZud3dl8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2441c04-60f1-441c-c9b3-94a2f14353f4"
      },
      "cell_type": "code",
      "source": [
        "H2.get_shape().as_list()  # [2, 2, 3]\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "a-caY1nivsPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sesh = tf.Session()\n",
        "sesh.run(tf.initialize_all_variables())\n",
        "sesh.run(H1, feed_dict={w:create_train_instance})\n",
        "\n",
        "for i in range(1000):\n",
        "  batch_v,batch_w = \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V1Iqi3RhdePB",
        "colab_type": "code",
        "outputId": "c7412972-aa10-4528-e892-1db5563cf882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "a=[[1,2,1],[0,0,0],[7,8,9]]\n",
        "b,c=np.split(a, [1,np.shape(a)[0]-1],0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-632b3e049d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Zgll0ezZcIw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c142c46-826a-44a8-cf48-782e6fc996ee"
      },
      "cell_type": "code",
      "source": [
        "create_train_instance(1,neg)[1:]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 1282, 13110, 10849, 4926, 2072]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}